{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f6a7f2",
   "metadata": {},
   "source": [
    "## Atividade Prática VI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9e932",
   "metadata": {},
   "source": [
    "Este trabalho tem como objetivo aplicar o algoritmo Random Forest na base de dados Madelon, desenvolvida para o NIPS 2003 Feature Selection Challenge. A base apresenta alta dimensionalidade e variáveis irrelevantes, tornando o problema de classificação desafiador. Foram realizados experimentos em dois cenários  \"dados normalizados e não normalizados\"   e comparadas três abordagens de predição: votação majoritária (hard voting), ponderada (weighted voting) e suave (soft voting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce699e8",
   "metadata": {},
   "source": [
    "Preparação do ambiente e importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6399fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0630d5f",
   "metadata": {},
   "source": [
    "# Download da base Madelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0a77318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos extraídos com sucesso!\n",
      "Conteúdo da pasta 'dataset/':\n",
      "['madelon_valid.labels', 'Dataset.pdf', 'MADELON']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zip_path = \"/home/emilly/Trabalho Topicos_florest/Madelon-RandomForest-Classification/madelon.zip\"\n",
    "extract_path = \"/home/emilly/Trabalho Topicos_florest/Madelon-RandomForest-Classification/dataset\"\n",
    "\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Arquivos extraídos com sucesso!\")\n",
    "print(\"Conteúdo da pasta 'dataset/':\")\n",
    "print(os.listdir(extract_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb2e206",
   "metadata": {},
   "source": [
    "Analise do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ff32315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões dos dados:\n",
      "X (atributos): (2000, 500)\n",
      "y (rótulos): (2000, 1)\n",
      "\n",
      "Primeiras linhas dos atributos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>477</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>463</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>487</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>488</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  490  491  492  493  \\\n",
       "0  485  477  537  479  452  471  491  476  475  473  ...  477  481  477  485   \n",
       "1  483  458  460  487  587  475  526  479  485  469  ...  463  478  487  338   \n",
       "2  487  542  499  468  448  471  442  478  480  477  ...  487  481  492  650   \n",
       "3  480  491  510  485  495  472  417  474  502  476  ...  491  480  474  572   \n",
       "4  484  502  528  489  466  481  402  478  487  468  ...  488  479  452  435   \n",
       "\n",
       "   494  495  496  497  498  499  \n",
       "0  511  485  481  479  475  496  \n",
       "1  513  486  483  492  510  517  \n",
       "2  506  501  480  489  499  498  \n",
       "3  454  469  475  482  494  461  \n",
       "4  486  508  481  504  495  511  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição das classes:\n",
      "   Classe  Frequência\n",
      "0      -1        1000\n",
      "1       1        1000\n",
      "\n",
      " Estatísticas dos atributos (amostra):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>481.7225</td>\n",
       "      <td>6.421769</td>\n",
       "      <td>462.0</td>\n",
       "      <td>477.00</td>\n",
       "      <td>482.0</td>\n",
       "      <td>486.00</td>\n",
       "      <td>503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>483.4525</td>\n",
       "      <td>30.186294</td>\n",
       "      <td>381.0</td>\n",
       "      <td>464.00</td>\n",
       "      <td>483.0</td>\n",
       "      <td>503.00</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>510.1660</td>\n",
       "      <td>38.899165</td>\n",
       "      <td>370.0</td>\n",
       "      <td>485.00</td>\n",
       "      <td>510.5</td>\n",
       "      <td>536.00</td>\n",
       "      <td>654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>483.3845</td>\n",
       "      <td>9.059895</td>\n",
       "      <td>453.0</td>\n",
       "      <td>477.00</td>\n",
       "      <td>483.0</td>\n",
       "      <td>490.00</td>\n",
       "      <td>519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>501.6125</td>\n",
       "      <td>41.389418</td>\n",
       "      <td>371.0</td>\n",
       "      <td>475.00</td>\n",
       "      <td>500.0</td>\n",
       "      <td>528.00</td>\n",
       "      <td>688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>479.2590</td>\n",
       "      <td>6.795956</td>\n",
       "      <td>459.0</td>\n",
       "      <td>475.00</td>\n",
       "      <td>479.0</td>\n",
       "      <td>484.00</td>\n",
       "      <td>505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>480.1095</td>\n",
       "      <td>40.575925</td>\n",
       "      <td>334.0</td>\n",
       "      <td>452.75</td>\n",
       "      <td>480.0</td>\n",
       "      <td>506.25</td>\n",
       "      <td>611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>476.5650</td>\n",
       "      <td>1.384461</td>\n",
       "      <td>471.0</td>\n",
       "      <td>476.00</td>\n",
       "      <td>477.0</td>\n",
       "      <td>477.00</td>\n",
       "      <td>481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>486.7935</td>\n",
       "      <td>15.043836</td>\n",
       "      <td>430.0</td>\n",
       "      <td>477.00</td>\n",
       "      <td>487.0</td>\n",
       "      <td>496.25</td>\n",
       "      <td>536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>478.7890</td>\n",
       "      <td>7.190920</td>\n",
       "      <td>455.0</td>\n",
       "      <td>474.00</td>\n",
       "      <td>479.0</td>\n",
       "      <td>484.00</td>\n",
       "      <td>503.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count      mean        std    min     25%    50%     75%    max\n",
       "0  2000.0  481.7225   6.421769  462.0  477.00  482.0  486.00  503.0\n",
       "1  2000.0  483.4525  30.186294  381.0  464.00  483.0  503.00  600.0\n",
       "2  2000.0  510.1660  38.899165  370.0  485.00  510.5  536.00  654.0\n",
       "3  2000.0  483.3845   9.059895  453.0  477.00  483.0  490.00  519.0\n",
       "4  2000.0  501.6125  41.389418  371.0  475.00  500.0  528.00  688.0\n",
       "5  2000.0  479.2590   6.795956  459.0  475.00  479.0  484.00  505.0\n",
       "6  2000.0  480.1095  40.575925  334.0  452.75  480.0  506.25  611.0\n",
       "7  2000.0  476.5650   1.384461  471.0  476.00  477.0  477.00  481.0\n",
       "8  2000.0  486.7935  15.043836  430.0  477.00  487.0  496.25  536.0\n",
       "9  2000.0  478.7890   7.190920  455.0  474.00  479.0  484.00  503.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "base_path = \"/home/emilly/Trabalho Topicos_florest/Madelon-RandomForest-Classification/dataset/MADELON\"\n",
    "train_data_path = os.path.join(base_path, \"madelon_train.data\")\n",
    "train_labels_path = os.path.join(base_path, \"madelon_train.labels\")\n",
    "\n",
    "\n",
    "X = pd.read_csv(train_data_path, sep=\" \", header=None)\n",
    "y = pd.read_csv(train_labels_path, sep=\" \", header=None)\n",
    "\n",
    "X = X.dropna(axis=1, how='all')\n",
    "\n",
    "print(\"Dimensões dos dados:\")\n",
    "print(f\"X (atributos): {X.shape}\")\n",
    "print(f\"y (rótulos): {y.shape}\\n\")\n",
    "\n",
    "print(\"Primeiras linhas dos atributos:\")\n",
    "display(X.head())\n",
    "\n",
    "print(\"Distribuição das classes:\")\n",
    "print(y.value_counts().rename_axis(\"Classe\").reset_index(name=\"Frequência\"))\n",
    "\n",
    "# Estatísticas básicas\n",
    "print(\"\\n Estatísticas dos atributos (amostra):\")\n",
    "display(X.describe().T.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c5e2a",
   "metadata": {},
   "source": [
    "##  Cenários de Classificação: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed9149",
   "metadata": {},
   "source": [
    "Dados não normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd68fa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho total após junção: 2600 amostras e 500 features\n",
      "Tamanho treino: 2080 | Tamanho teste: 520\n",
      "============================================\n",
      "CENÁRIO 1: SEM NORMALIZAÇÃO (HOLD-OUT 80/20)\n",
      "============================================\n",
      "Acurácia: 0.7058\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.77      0.72       260\n",
      "           1       0.74      0.64      0.69       260\n",
      "\n",
      "    accuracy                           0.71       520\n",
      "   macro avg       0.71      0.71      0.70       520\n",
      "weighted avg       0.71      0.71      0.70       520\n",
      "\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[200  60]\n",
      " [ 93 167]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Caminho base\n",
    "base_path = \"/home/emilly/Trabalho Topicos_florest/Madelon-RandomForest-Classification/dataset/MADELON\"\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "train_data_path = os.path.join(base_path, \"madelon_train.data\")\n",
    "train_labels_path = os.path.join(base_path, \"madelon_train.labels\")\n",
    "valid_data_path = os.path.join(base_path, \"madelon_valid.data\")\n",
    "valid_labels_path = os.path.join(base_path, \"madelon_valid.labels\")\n",
    "\n",
    "X_train = pd.read_csv(train_data_path, sep=\" \", header=None)\n",
    "y_train = pd.read_csv(train_labels_path, sep=\" \", header=None)\n",
    "\n",
    "X_valid = pd.read_csv(valid_data_path, sep=\" \", header=None)\n",
    "y_valid = pd.read_csv(valid_labels_path, sep=\" \", header=None)\n",
    "\n",
    "# Remover colunas vazias\n",
    "X_train = X_train.dropna(axis=1, how=\"all\")\n",
    "X_valid = X_valid.dropna(axis=1, how=\"all\")\n",
    "\n",
    "X_total = pd.concat([X_train, X_valid], ignore_index=True)\n",
    "y_total = pd.concat([y_train, y_valid], ignore_index=True).squeeze()\n",
    "\n",
    "print(f\"Tamanho total após junção: {X_total.shape[0]} amostras e {X_total.shape[1]} features\")\n",
    "\n",
    "\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "    X_total, y_total, test_size=0.2, random_state=42, stratify=y_total\n",
    ")\n",
    "\n",
    "print(f\"Tamanho treino: {X_train_final.shape[0]} | Tamanho teste: {X_test_final.shape[0]}\")\n",
    "\n",
    "# Modelo Random Forest\n",
    "modelo = RandomForestClassifier(\n",
    "    n_estimators=200, random_state=42, n_jobs=-1\n",
    ")\n",
    "modelo.fit(X_train_final, y_train_final)\n",
    "y_pred = modelo.predict(X_test_final)\n",
    "\n",
    "importances = modelo.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_features = indices[:20]\n",
    "\n",
    "X_train_reduzido = X_train_final.iloc[:, top_features]\n",
    "X_test_reduzido = X_test_final.iloc[:, top_features]\n",
    "\n",
    "print(\"============================================\")\n",
    "print(\"CENÁRIO 1: SEM NORMALIZAÇÃO (HOLD-OUT 80/20)\")\n",
    "print(\"============================================\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test_final, y_pred):.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test_final, y_pred))\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_test_final, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b59e695",
   "metadata": {},
   "source": [
    "Dados normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0daa1052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho total após junção: 2600 amostras e 500 features\n",
      "============================================\n",
      "CENÁRIO 2: COM NORMALIZAÇÃO (HOLD-OUT 80/20)\n",
      "============================================\n",
      "Acurácia: 0.7077\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.79      0.73       260\n",
      "           1       0.75      0.63      0.68       260\n",
      "\n",
      "    accuracy                           0.71       520\n",
      "   macro avg       0.71      0.71      0.71       520\n",
      "weighted avg       0.71      0.71      0.71       520\n",
      "\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[205  55]\n",
      " [ 97 163]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_path = \"/home/emilly/Trabalho Topicos_florest/Madelon-RandomForest-Classification/dataset/MADELON\"\n",
    "\n",
    "train_data_path = os.path.join(base_path, \"madelon_train.data\")\n",
    "train_labels_path = os.path.join(base_path, \"madelon_train.labels\")\n",
    "valid_data_path = os.path.join(base_path, \"madelon_valid.data\")\n",
    "valid_labels_path = os.path.join(base_path, \"madelon_valid.labels\")\n",
    "\n",
    "X_train = pd.read_csv(train_data_path, sep=\" \", header=None)\n",
    "y_train = pd.read_csv(train_labels_path, sep=\" \", header=None)\n",
    "\n",
    "X_valid = pd.read_csv(valid_data_path, sep=\" \", header=None)\n",
    "y_valid = pd.read_csv(valid_labels_path, sep=\" \", header=None)\n",
    "\n",
    "X_train = X_train.dropna(axis=1, how=\"all\")\n",
    "X_valid = X_valid.dropna(axis=1, how=\"all\")\n",
    "\n",
    "X_total = pd.concat([X_train, X_valid], ignore_index=True)\n",
    "y_total = pd.concat([y_train, y_valid], ignore_index=True).squeeze()\n",
    "\n",
    "print(f\"Tamanho total após junção: {X_total.shape[0]} amostras e {X_total.shape[1]} features\")\n",
    "\n",
    "# Divisão hold-out (80% treino, 20% teste)\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "    X_total, y_total, test_size=0.2, random_state=42, stratify=y_total\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "X_test_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "modelo = RandomForestClassifier(\n",
    "    n_estimators=300, random_state=42, n_jobs=-1\n",
    ")\n",
    "modelo.fit(X_train_scaled, y_train_final)\n",
    "y_pred = modelo.predict(X_test_scaled)\n",
    "\n",
    "print(\"============================================\")\n",
    "print(\"CENÁRIO 2: COM NORMALIZAÇÃO (HOLD-OUT 80/20)\")\n",
    "print(\"============================================\")\n",
    "print(f\"Acurácia: {accuracy_score(y_test_final, y_pred):.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test_final, y_pred))\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_test_final, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f302b",
   "metadata": {},
   "source": [
    "# Aplicação do Algoritmo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8246dccb",
   "metadata": {},
   "source": [
    "Aplicação do algoritmo Random Forest na classificação dos dados utilizando os \n",
    "seguintes métodos para determinar a predição:\n",
    "* votação majoritária\n",
    "* votação ponderada\n",
    "* votação suave (soft voting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174eba1",
   "metadata": {},
   "source": [
    "CENÁRIO Não NORMALIZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33e9a440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho total após junção: 2600 amostras e 500 features\n",
      "\n",
      "============================================\n",
      "RESULTADOS - CENÁRIO NÃO NORMALIZADO (80/20)\n",
      "============================================\n",
      "                     Acurácia  Precisão  Recall  F1-Score   Kappa\n",
      "Votação Majoritária    0.7077    0.7133  0.7077    0.7058  0.4154\n",
      "Votação Suave          0.7077    0.7133  0.7077    0.7058  0.4154\n",
      "Votação Ponderada      0.5365    0.7357  0.5365    0.4124  0.0731\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_path = \"/home/emilly/Trabalho Topicos_florest/Madelon-RandomForest-Classification/dataset/MADELON\"\n",
    "\n",
    "train_data_path = os.path.join(base_path, \"madelon_train.data\")\n",
    "train_labels_path = os.path.join(base_path, \"madelon_train.labels\")\n",
    "valid_data_path = os.path.join(base_path, \"madelon_valid.data\")\n",
    "valid_labels_path = os.path.join(base_path, \"madelon_valid.labels\")\n",
    "\n",
    "X_train = pd.read_csv(train_data_path, sep=\" \", header=None)\n",
    "y_train = pd.read_csv(train_labels_path, sep=\" \", header=None)\n",
    "X_valid = pd.read_csv(valid_data_path, sep=\" \", header=None)\n",
    "y_valid = pd.read_csv(valid_labels_path, sep=\" \", header=None)\n",
    "\n",
    "# Remove colunas vazias\n",
    "X_train = X_train.dropna(axis=1, how=\"all\")\n",
    "X_valid = X_valid.dropna(axis=1, how=\"all\")\n",
    "\n",
    "# Junta treino + validação\n",
    "X_total = pd.concat([X_train, X_valid], ignore_index=True)\n",
    "y_total = pd.concat([y_train, y_valid], ignore_index=True).squeeze()\n",
    "\n",
    "print(f\"Tamanho total após junção: {X_total.shape[0]} amostras e {X_total.shape[1]} features\")\n",
    "\n",
    "\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "    X_total, y_total, test_size=0.2, random_state=42, stratify=y_total\n",
    ")\n",
    "\n",
    "modelo = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "modelo.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Predição direta (hard voting)\n",
    "pred_hard = modelo.predict(X_test_final)\n",
    "\n",
    "# Probabilidades preditas (para simular votações suaves/ponderadas)\n",
    "prob = modelo.predict_proba(X_test_final)\n",
    "\n",
    "# Votação suave (soft voting)\n",
    "pred_soft = modelo.classes_[prob.argmax(axis=1)]\n",
    "\n",
    "# Votação ponderada (weighted voting): aplica pesos simulados nas probabilidades\n",
    "pesos = np.linspace(0.5, 1.0, prob.shape[1])\n",
    "pred_weighted = modelo.classes_[np.argmax(prob * pesos, axis=1)]\n",
    "\n",
    "def avaliar(y_true, y_pred):\n",
    "    return {\n",
    "        \"Acurácia\": accuracy_score(y_true, y_pred),\n",
    "        \"Precisão\": precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        \"F1-Score\": f1_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        \"Kappa\": cohen_kappa_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "\n",
    "resultados = {\n",
    "    \"Votação Majoritária\": avaliar(y_test_final, pred_hard),\n",
    "    \"Votação Suave\": avaliar(y_test_final, pred_soft),\n",
    "    \"Votação Ponderada\": avaliar(y_test_final, pred_weighted),\n",
    "}\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados).T.round(4)\n",
    "print(\"\\n============================================\")\n",
    "print(\"RESULTADOS - CENÁRIO NÃO NORMALIZADO (80/20)\")\n",
    "print(\"============================================\")\n",
    "print(df_resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc803adf",
   "metadata": {},
   "source": [
    "CENÁRIO NORMALIZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d3e1d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho total após junção: 2600 amostras e 500 features\n",
      "\n",
      "============================================\n",
      "RESULTADOS - CENÁRIO NORMALIZADO (80/20)\n",
      "============================================\n",
      "                     Acurácia  Precisão  Recall  F1-Score   Kappa\n",
      "Votação Majoritária    0.7077    0.7133  0.7077    0.7058  0.4154\n",
      "Votação Suave          0.7077    0.7133  0.7077    0.7058  0.4154\n",
      "Votação Ponderada      0.5346    0.7340  0.5346    0.4086  0.0692\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    ")\n",
    "\n",
    "\n",
    "base_path = \"/home/emilly/Trabalho Topicos_florest/Madelon-RandomForest-Classification/dataset/MADELON\"\n",
    "\n",
    "train_data_path = os.path.join(base_path, \"madelon_train.data\")\n",
    "train_labels_path = os.path.join(base_path, \"madelon_train.labels\")\n",
    "valid_data_path = os.path.join(base_path, \"madelon_valid.data\")\n",
    "valid_labels_path = os.path.join(base_path, \"madelon_valid.labels\")\n",
    "\n",
    "X_train = pd.read_csv(train_data_path, sep=\" \", header=None)\n",
    "y_train = pd.read_csv(train_labels_path, sep=\" \", header=None)\n",
    "X_valid = pd.read_csv(valid_data_path, sep=\" \", header=None)\n",
    "y_valid = pd.read_csv(valid_labels_path, sep=\" \", header=None)\n",
    "\n",
    "# Remove colunas vazias\n",
    "X_train = X_train.dropna(axis=1, how=\"all\")\n",
    "X_valid = X_valid.dropna(axis=1, how=\"all\")\n",
    "\n",
    "# Junta treino + validação\n",
    "X_total = pd.concat([X_train, X_valid], ignore_index=True)\n",
    "y_total = pd.concat([y_train, y_valid], ignore_index=True).squeeze()\n",
    "\n",
    "print(f\"Tamanho total após junção: {X_total.shape[0]} amostras e {X_total.shape[1]} features\")\n",
    "\n",
    "\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "    X_total, y_total, test_size=0.2, random_state=42, stratify=y_total\n",
    ")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "X_test_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "\n",
    "modelo = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "modelo.fit(X_train_scaled, y_train_final)\n",
    "\n",
    "\n",
    "# Predições normais (hard)\n",
    "pred_hard = modelo.predict(X_test_scaled)\n",
    "\n",
    "# Predições de probabilidade (soft)\n",
    "\n",
    "prob = modelo.predict_proba(X_test_scaled)\n",
    "\n",
    "# Simulação da votação suave\n",
    "pred_soft = modelo.classes_[prob.argmax(axis=1)]\n",
    "\n",
    "\n",
    "pesos = np.linspace(0.5, 1.0, prob.shape[1])\n",
    "pred_weighted = modelo.classes_[np.argmax(prob * pesos, axis=1)]\n",
    "\n",
    "\n",
    "def avaliar(y_true, y_pred):\n",
    "    return {\n",
    "        \"Acurácia\": accuracy_score(y_true, y_pred),\n",
    "        \"Precisão\": precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        \"F1-Score\": f1_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "        \"Kappa\": cohen_kappa_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "\n",
    "resultados = {\n",
    "    \"Votação Majoritária\": avaliar(y_test_final, pred_hard),\n",
    "    \"Votação Suave\": avaliar(y_test_final, pred_soft),\n",
    "    \"Votação Ponderada\": avaliar(y_test_final, pred_weighted),\n",
    "}\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados).T.round(4)\n",
    "print(\"\\n============================================\")\n",
    "print(\"RESULTADOS - CENÁRIO NORMALIZADO (80/20)\")\n",
    "print(\"============================================\")\n",
    "print(df_resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8104e1a",
   "metadata": {},
   "source": [
    "# Resultados e Discussão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e82ac",
   "metadata": {},
   "source": [
    "Graficos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd6d82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
